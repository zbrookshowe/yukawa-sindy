{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8913cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import Yukawa_SINDy as ys\n",
    "import pysindy as ps\n",
    "from importlib import reload\n",
    "\n",
    "# import scaling constant from working directory\n",
    "import pickle as pkl\n",
    "with open('scaling_const.float','rb') as f:\n",
    "    A = pkl.load(f)\n",
    "\n",
    "# ignore warnings generated from using LaTeX coding in matplotlib label strings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', message = 'invalid escape sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included to update Yukawa_SINDy.py version used in this notebook as changes are made\n",
    "reload(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.autolimit_mode'] = 'data'\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['figure.figsize'] = (8,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c2165",
   "metadata": {},
   "source": [
    "list of functions exported to 'Yukawa_SINDy.py'\n",
    "\n",
    "- `generate_training_data`\n",
    "- `plot_complexities`\n",
    "- `scan_thresholds`\n",
    "- `generate_libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsim = ys.Yukawa_simulation()\n",
    "testsim.simulate(3, 0.001, 0.5,0.01,scaled=True)\n",
    "testsim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = testsim.x[:,0]\n",
    "avg_pos = np.average(np.abs(positions))\n",
    "rms_pos = np.sqrt(np.sum(positions**2) / len(positions))\n",
    "print(\"avg position:\", avg_pos)\n",
    "print(\"rms position:\", rms_pos)\n",
    "velocities = testsim.x[:,1]\n",
    "avg_vel = np.average(np.abs(velocities))\n",
    "rms_vel = np.sqrt(np.sum(velocities**2) / len(velocities))\n",
    "print(\"avg velocity:\", avg_vel)\n",
    "print(\"rms velocity:\", rms_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804be64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise and calculate signal-to-noise ratio (SNR) using avg positions\n",
    "noise_level = 0.01\n",
    "testsim.add_gaussian_noise(noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_pos = avg_pos / noise_level\n",
    "SNR_pos_dB = 10*np.log10(SNR_pos)\n",
    "print(\"position SNR (dB):\", SNR_pos_dB)\n",
    "SNR_vel = avg_vel / noise_level\n",
    "SNR_vel_dB = 10*np.log10(SNR_vel)\n",
    "print(\"velocity SNR (dB):\", SNR_vel_dB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb5272",
   "metadata": {},
   "source": [
    "# Analysis of Yukawa 2-body data using Weak SINDy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ab0b8",
   "metadata": {},
   "source": [
    "## `std_dev=0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1832a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set var 'noise_level' for this section\n",
    "noise_level = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516fdc1",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a weak SINDy analysis on 2-body trajectories to see if the sparse recovery of simulation coefficients is improved. Results from the analysis of the same system using only one trajectory with strong-form SINDy (the original formulation) is shown in the notebook 'Yukawa2body.ipynb'.\n",
    "\n",
    "Here, we will start by using one trajectory of the 2-body equations, as we did before, and then possibly extend to more trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c62f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim001 = ys.Yukawa_simulation()\n",
    "sim001.simulate(5, dt=0.001, x0=0.5, v0=0.01, scaled=True)\n",
    "sim001.add_gaussian_noise(noise_level=noise_level)\n",
    "sim001.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, A, 0.05*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim001, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbad5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d10931",
   "metadata": {},
   "source": [
    "the model is fit at `threshold=0.35*A` to a very good approximation with the weak formulation. In this parameter range, the strong form does not really come close to the correct equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 10*A, 0.5*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim001, thresholds, verbose=True)\n",
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c1618",
   "metadata": {},
   "source": [
    "From this, we can see that strong form discovers nothing meaningful, even when the threshold is at $10A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f87def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to be used for spot checking whatever threshold\n",
    "threshold = 0.35*A\n",
    "opt = ps.STLSQ(threshold=threshold)\n",
    "weak_lib, strong_lib = ys.generate_libraries(sim001.t)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"], feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(sim001.x)\n",
    "weak_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56bef4",
   "metadata": {},
   "source": [
    "## `std_dev=0.10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eeec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc530ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim010 = ys.Yukawa_simulation()\n",
    "sim010.simulate(5, dt=0.001,x0=0.5,v0=0.01,scaled=True)\n",
    "sim010.add_gaussian_noise(noise_level=noise_level)\n",
    "sim010.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255eab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 2*A, 0.2*A)\n",
    "print(thresholds)\n",
    "print(thresholds/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1*A, 0.02*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sim010, thresholds, verbose=True)\n",
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bad081",
   "metadata": {},
   "source": [
    "With a single trajectory, WSINDy does not recover the correct equations of motion, but it does discover the leading terms along with the presence of extraneous terms. This improves with the multiple trajectories approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cead34e",
   "metadata": {},
   "source": [
    "## Multiple trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e5158",
   "metadata": {},
   "source": [
    "We can also generate many trajectories with different initial conditions and use that to train SINDy. This is what we were already doing for the three-body case, but we can see how much it improves the performance of SINDy here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea694083",
   "metadata": {},
   "source": [
    "Note that we generate random initial conditions in the following way:\n",
    "\n",
    "- *Initial positions*: taken from a normal distribution centered at 1 with std. dev. of 0.2\n",
    "- *Initial velocities*: taken from a normal distribution centered at 0.01 with a std. dev. of 0.002, also with a random +/- sign.\n",
    "\n",
    "This was done carefully so as to avoid there being zeros in the initial conditions, which create problems for the solver and for SINDy because of the presence of the rational terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d5e25",
   "metadata": {},
   "source": [
    "### `noise_level=0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'noise_level' back to 0.01\n",
    "noise_level = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb793527",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims001 = ys.generate_training_data(noise_level=noise_level, scaled=True, mu_x0s=0.5)\n",
    "sims001[73].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38524a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims001[100].is_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 0.2*A, 0.01*A)\n",
    "thresholds, complexities = ys.scan_thresholds(sims001, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e678280",
   "metadata": {},
   "source": [
    "So the \"correct model\" is discovered by the weak form when `threshold=0.04*A` with no small extraneous terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds,complexities, noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb8df1",
   "metadata": {},
   "source": [
    "### `noise_level=0.10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff17a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims010 = ys.generate_training_data(noise_level=noise_level, mu_x0s=0.5, scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims010[38].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = np.arange(0, 0.2, 0.01)\n",
    "thresholds = np.concatenate((np.arange(0, 0.2*A, 0.01*A), np.arange(0.2*A, 1.0*A, 0.05*A), np.arange(1.0*A, 5.0*A, 0.5*A)))\n",
    "libs = ys.generate_libraries(sims010[0].t)\n",
    "x_train010 = [sim.x for sim in sims010]\n",
    "t_train010 = sims010[0].t\n",
    "thresholds, complexities = ys.scan_thresholds(sims010, thresholds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818015a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.plot_complexities(thresholds, complexities, noise_level=noise_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd942dc",
   "metadata": {},
   "source": [
    "Noticing as these models are coming out that there is a long series of the exact same models between 0.05 and 0.18 in the weak case, with a few steps happening for the strong models. \n",
    "It might be interesting to look into an optimal threshold step size that would minimize SINDy discovering the same model over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [sim.x for sim in sims010] # if sim.x.shape[0] == 5000]\n",
    "t_train = sims010[0].t\n",
    "weak_lib, strong_lib = generate_libraries(t_train)\n",
    "opt = ps.STLSQ(threshold=0.5)\n",
    "strong_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=strong_lib, optimizer=opt)\n",
    "strong_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "strong_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ps.STLSQ(threshold=0.2)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "weak_model.print(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad3ab8",
   "metadata": {},
   "source": [
    "The weak form of SINDy discovers the correct underlying model with a threshold of 0.2, while strong-form SINDy does not discover the correct model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d8d32",
   "metadata": {},
   "source": [
    "### `noise_level=0.20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1cd73",
   "metadata": {},
   "source": [
    "### `noise_level=0.50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for spot-checking weak models\n",
    "x_train = [sim.x for sim in sims050]\n",
    "t_train = sims050[0].t\n",
    "\n",
    "weak_lib, strong_lib = generate_libraries(t_train)\n",
    "opt = ps.STLSQ(threshold=0.0001)\n",
    "weak_model = ps.SINDy(feature_names=[\"x\", \"v\"],feature_library=weak_lib, optimizer=opt)\n",
    "weak_model.fit(x_train, t=t_train, multiple_trajectories=True)\n",
    "weak_model.print(precision=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
