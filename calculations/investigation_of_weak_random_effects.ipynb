{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0251ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf01339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysindy as ps\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import Yukawa_SINDy as ys\n",
    "import cross_validation as cv\n",
    "\n",
    "# import scaling constant from working directory and declare as global variable\n",
    "with open('scaling_const.float','rb') as f:\n",
    "    SCALING_CONST = pkl.load(f)\n",
    "\n",
    "from importlib import reload\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549310e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(cv)\n",
    "reload(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4fe64",
   "metadata": {},
   "source": [
    "# Random effects of weak SINDy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a58bf",
   "metadata": {},
   "source": [
    "Weak SINDy chooses a random sampling of subdomains every time such a model is fit. Here, we will investigate how the number of those subdomains affects the quality of the output by looking at the predictive error and the \"true error\", or \"coefficient error\". The predictive error is simply how well the SINDy prediction of the derivative of the data does compared to the calculated error from the Finite Difference method. The coefficient error is the rmse difference between the true coefficient matrix and the learned SINDy coefficient matrix. This gives us an idea of how well SINDy was able to identify the correct model form noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25755d4",
   "metadata": {},
   "source": [
    "Let's investigate how the number of subdomains parameter `K` affects the SINDy fitting. I don't perceive that it will change the way that the predictive error is related to the true error, but let's try it for 4 different values of `K`. This will all be with one value of the threshold and one noise level. We found that for a relatively high value of noise, `noise_level = 0.1`, a threshold value of 0.4 often finds the correct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf784f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "noise_level = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee437d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "sim_list = ys.generate_training_data(mu_x0s=0.5, noise_level=noise_level, scaled=True)\n",
    "\n",
    "t_data = sim_list[0].t\n",
    "x_train_list = [sim.x for sim in sim_list[0:150]]\n",
    "x_train = np.array(x_train_list)\n",
    "x_test = [sim.x for sim in sim_list[150:200]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50266724",
   "metadata": {},
   "source": [
    "## `K = 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4283cdc",
   "metadata": {},
   "source": [
    "This is the default value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fitted \"test model\" SINDy instance to pass into the \n",
    "# 'kfold_training' function, this way it gets all the relevant \n",
    "# SINDy parameters\n",
    "K=100\n",
    "weak_library = ys.generate_weak_Yukawa_library(t_data,K=K)\n",
    "optimizer = ps.STLSQ(threshold=threshold)\n",
    "test_model = ps.SINDy(\n",
    "    optimizer = optimizer,\n",
    "    feature_library = weak_library\n",
    ")\n",
    "test_model.fit(x_train_list, t_data, multiple_trajectories=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d222a",
   "metadata": {},
   "source": [
    "Now, we use the func `kfold_training` to generate a list of 10 fitted SINDy objects using the weak formulation with a different random sampling of subdomains for the numerical integration. This will give us a list of models and their \"predictive error\" which is the error generated by the learned SINDy model for the test data during the k-fold validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05844db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models, all_rmse_predictive = cv.kfold_training(\n",
    "    x_train,\n",
    "    t_data,\n",
    "    10,\n",
    "    test_model  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c209c",
   "metadata": {},
   "source": [
    "We can now calculate the error between the learned coefficients of SINDy and the correct coefficient matrix `correct_coefs`, which has the form\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "    0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 0 & A & 0 & A & 0 & 0 & 0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "Where $A$ is the scaling constant, loaded in above, which has the value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a24ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALING_CONST # A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d55551",
   "metadata": {},
   "source": [
    "We can now calculate the rmse of the learned coefficient matrices and the correct coefficient matrix, represented as `rmse_true` in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ede1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_coefs = np.array(\n",
    "    [[0, 1] + 8*[0],\n",
    "     [0, 0, SCALING_CONST, 0, SCALING_CONST] + 5*[0]\n",
    "    ]\n",
    ")\n",
    "all_coefs = np.array([model.coefficients() for model in all_models])\n",
    "all_rmse_true = np.array([])\n",
    "for coefs in all_coefs:\n",
    "    rmse_true = root_mean_squared_error(correct_coefs, coefs)\n",
    "    all_rmse_true = np.hstack((all_rmse_true, rmse_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f995c4d",
   "metadata": {},
   "source": [
    "Now, we can take a look at all the individual models separately, along with their predictive error `rmse_predictive` and error of the coefficient matrix with the true coefficients `rmse_true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427039fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(all_models):\n",
    "    print(f\"Model {i}\")\n",
    "    model.print()\n",
    "    print(f\"pred rmse: {all_rmse_predictive[i]:.4f}\")\n",
    "    print(f\"true rmse: {all_rmse_true[i]:.4f}\")\n",
    "    print(60*'-' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ed799",
   "metadata": {},
   "source": [
    "For ease of reading, here are the models with the lowest predictive rmse and the one which has coefficients which are closest to the true ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best prediction:\")\n",
    "print(f\"Model {all_rmse_predictive.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive.min()}\")\n",
    "print(f\"True coef rmse: {all_rmse_true[all_rmse_predictive.argmin()]}\")\n",
    "all_models[all_rmse_predictive.argmin()].print()\n",
    "print(60*'-' + '\\n')\n",
    "\n",
    "print(\"Closest to true:\")\n",
    "print(f\"Model {all_rmse_true.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive[all_rmse_true.argmin()]}\")\n",
    "print(f\"True coef rmse: {all_rmse_true.min()}\")\n",
    "all_models[all_rmse_true.argmin()].print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b40a2",
   "metadata": {},
   "source": [
    "Next, we can look at the true coefficient error plotted against the predictive error and see that they are loosely *negatively* correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_rmse_predictive, all_rmse_true, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Predictive error\")\n",
    "ax.set_ylabel(\"Error with true coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3509e",
   "metadata": {},
   "source": [
    "Now, we can look at a Pareto plot of the predictive errors against the number of terms, or complexities, of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb365c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complexities, or number of terms, of all models\n",
    "all_complexities = np.array([])\n",
    "for model in all_models:\n",
    "    complexity = np.count_nonzero(model.coefficients())\n",
    "    all_complexities = np.hstack((all_complexities, complexity))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_complexities, all_rmse_predictive, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Number of terms\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_ylabel(\"Predictive error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf8097",
   "metadata": {},
   "source": [
    "## `K = 300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6922827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K\n",
    "K=300\n",
    "\n",
    "# generate fitted \"test model\" SINDy instance to pass into the \n",
    "# 'kfold_training' function, this way it gets all the relevant \n",
    "# SINDy parameters\n",
    "weak_library = ys.generate_weak_Yukawa_library(t_data,K=K)\n",
    "optimizer = ps.STLSQ(threshold=threshold)\n",
    "test_model = ps.SINDy(\n",
    "    optimizer = optimizer,\n",
    "    feature_library = weak_library\n",
    ")\n",
    "test_model.fit(x_train_list, t_data, multiple_trajectories=True)\n",
    "\n",
    "# perform kfold cross-val\n",
    "all_models, all_rmse_predictive = cv.kfold_training(\n",
    "    x_train,\n",
    "    t_data,\n",
    "    10,\n",
    "    test_model  \n",
    ")\n",
    "\n",
    "# collect coefficients\n",
    "all_coefs = np.array([model.coefficients() for model in all_models])\n",
    "all_rmse_true = np.array([])\n",
    "for coefs in all_coefs:\n",
    "    rmse_true = root_mean_squared_error(correct_coefs, coefs)\n",
    "    all_rmse_true = np.hstack((all_rmse_true, rmse_true))\n",
    "\n",
    "# print all models\n",
    "for i, model in enumerate(all_models):\n",
    "    print(f\"Model {i}\")\n",
    "    model.print()\n",
    "    print(f\"pred rmse: {all_rmse_predictive[i]:.4f}\")\n",
    "    print(f\"true rmse: {all_rmse_true[i]:.4f}\")\n",
    "    print(60*'-' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ceecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best prediction:\")\n",
    "print(f\"Model {all_rmse_predictive.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive.min()}\")\n",
    "print(f\"True coef rmse: {all_rmse_true[all_rmse_predictive.argmin()]}\")\n",
    "all_models[all_rmse_predictive.argmin()].print()\n",
    "print(60*'-' + '\\n')\n",
    "\n",
    "print(\"Closest to true:\")\n",
    "print(f\"Model {all_rmse_true.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive[all_rmse_true.argmin()]}\")\n",
    "print(f\"True coef rmse: {all_rmse_true.min()}\")\n",
    "all_models[all_rmse_true.argmin()].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_rmse_predictive, all_rmse_true, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Predictive error\")\n",
    "ax.set_ylabel(\"Error with true coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complexities, or number of terms, of all models\n",
    "all_complexities = np.array([])\n",
    "for model in all_models:\n",
    "    complexity = np.count_nonzero(model.coefficients())\n",
    "    all_complexities = np.hstack((all_complexities, complexity))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_complexities, all_rmse_predictive, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Number of terms\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_ylabel(\"Predictive error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42ad78",
   "metadata": {},
   "source": [
    "## `K = 500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cffb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K\n",
    "K=500\n",
    "\n",
    "# generate fitted \"test model\" SINDy instance to pass into the \n",
    "# 'kfold_training' function, this way it gets all the relevant \n",
    "# SINDy parameters\n",
    "weak_library = ys.generate_weak_Yukawa_library(t_data,K=K)\n",
    "optimizer = ps.STLSQ(threshold=threshold)\n",
    "test_model = ps.SINDy(\n",
    "    optimizer = optimizer,\n",
    "    feature_library = weak_library\n",
    ")\n",
    "test_model.fit(x_train_list, t_data, multiple_trajectories=True)\n",
    "\n",
    "# perform kfold cross-val\n",
    "all_models, all_rmse_predictive = cv.kfold_training(\n",
    "    x_train,\n",
    "    t_data,\n",
    "    10,\n",
    "    test_model  \n",
    ")\n",
    "\n",
    "# collect coefficients\n",
    "all_coefs = np.array([model.coefficients() for model in all_models])\n",
    "all_rmse_true = np.array([])\n",
    "for coefs in all_coefs:\n",
    "    rmse_true = root_mean_squared_error(correct_coefs, coefs)\n",
    "    all_rmse_true = np.hstack((all_rmse_true, rmse_true))\n",
    "\n",
    "# print all models\n",
    "for i, model in enumerate(all_models):\n",
    "    print(f\"Model {i}\")\n",
    "    model.print()\n",
    "    print(f\"pred rmse: {all_rmse_predictive[i]:.4f}\")\n",
    "    print(f\"true rmse: {all_rmse_true[i]:.4f}\")\n",
    "    print(60*'-' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ceecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best prediction:\")\n",
    "print(f\"Model {all_rmse_predictive.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive.min()}\")\n",
    "print(f\"True coef rmse: {all_rmse_true[all_rmse_predictive.argmin()]}\")\n",
    "all_models[all_rmse_predictive.argmin()].print()\n",
    "print(60*'-' + '\\n')\n",
    "\n",
    "print(\"Closest to true:\")\n",
    "print(f\"Model {all_rmse_true.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive[all_rmse_true.argmin()]}\")\n",
    "print(f\"True coef rmse: {all_rmse_true.min()}\")\n",
    "all_models[all_rmse_true.argmin()].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_rmse_predictive, all_rmse_true, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Predictive error\")\n",
    "ax.set_ylabel(\"Error with true coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complexities, or number of terms, of all models\n",
    "all_complexities = np.array([])\n",
    "for model in all_models:\n",
    "    complexity = np.count_nonzero(model.coefficients())\n",
    "    all_complexities = np.hstack((all_complexities, complexity))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_complexities, all_rmse_predictive, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Number of terms\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_ylabel(\"Predictive error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d5119",
   "metadata": {},
   "source": [
    "## `K = 700`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca52e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K\n",
    "K=700\n",
    "\n",
    "# generate fitted \"test model\" SINDy instance to pass into the \n",
    "# 'kfold_training' function, this way it gets all the relevant \n",
    "# SINDy parameters\n",
    "weak_library = ys.generate_weak_Yukawa_library(t_data,K=K)\n",
    "optimizer = ps.STLSQ(threshold=threshold)\n",
    "test_model = ps.SINDy(\n",
    "    optimizer = optimizer,\n",
    "    feature_library = weak_library\n",
    ")\n",
    "test_model.fit(x_train_list, t_data, multiple_trajectories=True)\n",
    "\n",
    "# perform kfold cross-val\n",
    "all_models, all_rmse_predictive = cv.kfold_training(\n",
    "    x_train,\n",
    "    t_data,\n",
    "    10,\n",
    "    test_model  \n",
    ")\n",
    "\n",
    "# collect coefficients\n",
    "all_coefs = np.array([model.coefficients() for model in all_models])\n",
    "all_rmse_true = np.array([])\n",
    "for coefs in all_coefs:\n",
    "    rmse_true = root_mean_squared_error(correct_coefs, coefs)\n",
    "    all_rmse_true = np.hstack((all_rmse_true, rmse_true))\n",
    "\n",
    "# print all models\n",
    "for i, model in enumerate(all_models):\n",
    "    print(f\"Model {i}\")\n",
    "    model.print()\n",
    "    print(f\"pred rmse: {all_rmse_predictive[i]:.4f}\")\n",
    "    print(f\"true rmse: {all_rmse_true[i]:.4f}\")\n",
    "    print(60*'-' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42290a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best prediction:\")\n",
    "print(f\"Model {all_rmse_predictive.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive.min()}\")\n",
    "print(f\"True coef rmse: {all_rmse_true[all_rmse_predictive.argmin()]}\")\n",
    "all_models[all_rmse_predictive.argmin()].print()\n",
    "print(60*'-' + '\\n')\n",
    "\n",
    "print(\"Closest to true:\")\n",
    "print(f\"Model {all_rmse_true.argmin()}\")\n",
    "print(f\"Predictive rmse: {all_rmse_predictive[all_rmse_true.argmin()]}\")\n",
    "print(f\"True coef rmse: {all_rmse_true.min()}\")\n",
    "all_models[all_rmse_true.argmin()].print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_rmse_predictive, all_rmse_true, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Predictive error\")\n",
    "ax.set_ylabel(\"Error with true coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fd56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate complexities, or number of terms, of all models\n",
    "all_complexities = np.array([])\n",
    "for model in all_models:\n",
    "    complexity = np.count_nonzero(model.coefficients())\n",
    "    all_complexities = np.hstack((all_complexities, complexity))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_complexities, all_rmse_predictive, 'o')\n",
    "ax.set_title(f\"K = {K}\")\n",
    "ax.set_xlabel(\"Number of terms\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_ylabel(\"Predictive error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d24ab",
   "metadata": {},
   "source": [
    "## All code generating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_errors_and_complexity(K, x_train, t_train, threshold, n_folds):\n",
    "\n",
    "    global SCALING_CONST\n",
    "\n",
    "    # unpack x_train and convert to list for 'fit' method\n",
    "    x_train_list = [traj for traj in x_train]\n",
    "\n",
    "    weak_library = ys.generate_weak_Yukawa_library(t_data, K=K)\n",
    "    optimizer = ps.STLSQ(threshold=threshold)\n",
    "    test_model = ps.SINDy(\n",
    "        optimizer=optimizer,\n",
    "        feature_library=weak_library,\n",
    "        feature_names=['x','v']\n",
    "    )\n",
    "    test_model.fit(x_train_list, t_train, multiple_trajectories=True)\n",
    "\n",
    "    # perform kfold cross-validation\n",
    "    all_models, all_rmse_predictive = cv.kfold_training(\n",
    "        x_train,\n",
    "        t_data,\n",
    "        n_folds,\n",
    "        test_model\n",
    "    )\n",
    "\n",
    "    # collect coefficients and complexities\n",
    "    all_coefs = np.array([model.coefficients() for model in all_models])\n",
    "    all_complexities = np.array([np.count_nonzero(coefs) for coefs in all_coefs])\n",
    "\n",
    "    # calculate \"true error\"\n",
    "    all_rmse_true = np.array([])\n",
    "    correct_coefs = np.array(\n",
    "        [[0, 1] + 8*[0],\n",
    "        [0, 0, SCALING_CONST, 0, SCALING_CONST] + 5*[0]\n",
    "        ]\n",
    "    )\n",
    "    for coefs in all_coefs:\n",
    "        rmse_true = root_mean_squared_error(correct_coefs, coefs)\n",
    "        all_rmse_true = np.hstack((all_rmse_true, rmse_true))\n",
    "    \n",
    "    return all_complexities, all_rmse_predictive, all_rmse_true\n",
    "        \n",
    "\n",
    "def K_param_scan(K_grid: list, n_repeat: int, x_train, t_train, threshold: float=0.4, n_folds: int=10):\n",
    "    n_models = n_repeat * n_folds\n",
    "    n_metrics = 3\n",
    "    all_metrics = np.array([]).reshape((0,n_models,n_metrics))\n",
    "    for K in K_grid:\n",
    "        print(K)\n",
    "        all_metrics_K = np.array([]).reshape((0, n_metrics))\n",
    "        for n in range(n_repeat):\n",
    "            print(n)\n",
    "            metrics_K = calc_errors_and_complexity(K, x_train, t_train, threshold=threshold, n_folds=n_folds)\n",
    "            # transform to array with dims (10, 3)\n",
    "            metrics_K = np.array(metrics_K).T\n",
    "            all_metrics_K = np.concatenate((all_metrics_K, metrics_K), axis=0)\n",
    "        \n",
    "        # add dim to all_metrics_K to concatenate\n",
    "        all_metrics_K.resize((1,) + all_metrics_K.shape)\n",
    "        print(all_metrics_K, all_metrics_K.shape)\n",
    "        print(all_metrics, all_metrics.shape)\n",
    "        all_metrics = np.concatenate((all_metrics, all_metrics_K), axis=0)\n",
    "    \n",
    "    # redefine all_metrics to include metadata\n",
    "    all_metrics = xr.DataArray(\n",
    "        all_metrics,\n",
    "        coords = {\"K\": K_grid, \"metric\": [\"complexity\", \"predictive error\", \"coefficient error\"]},\n",
    "        dims = [\"K\", \"model\", \"metric\"]\n",
    "    )\n",
    "    \n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16012d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to fix, args of kparamscan need to be passed or something\n",
    "def generate_or_load_data(results_directory='calculations/weak_random_effect_results/', filename='all_metrics.obj'):\n",
    "    filepath = results_directory + filename\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            all_metrics = pkl.load(f)\n",
    "    else:\n",
    "        K_grid = [100, 300, 500, 700]\n",
    "        n_repeat = 4\n",
    "        all_metrics = K_param_scan(K_grid, n_repeat, x_train, t_data, threshold)\n",
    "\n",
    "        # save results\n",
    "        if not os.path.exists(results_directory):\n",
    "            os.makedirs(results_directory)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pkl.dump(all_metrics, f)\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = generate_or_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_results(all_metrics: xr.DataArray, plot_num_models: bool, plot_model_pareto: bool, use_color: bool):\n",
    "    # Check arg types, check if args are valid\n",
    "    if not (isinstance(plot_num_models, bool) and isinstance(plot_model_pareto, bool) and isinstance(use_color, bool)):\n",
    "        raise TypeError(\"plot_num_models, plot_model_pareto, and use_color args are boolean flags\")\n",
    "    if not (plot_num_models or plot_model_pareto): \n",
    "        raise ValueError(\"at least one of the args plot_num_models, plot_model_pareto, or use_color must be `True`\")\n",
    "\n",
    "    # create shared min and max for predictive error \n",
    "    # (only needed if plot_num_models and plot_model_pareto)\n",
    "    all_rmse_pred = all_metrics.sel(metric=\"predictive error\")\n",
    "    pad = (all_rmse_pred.max() - all_rmse_pred.min()) / 20\n",
    "    lower_pred = all_rmse_pred.min() - pad\n",
    "    upper_pred = all_rmse_pred.max() + pad\n",
    "\n",
    "    # create shared min and max for number of terms\n",
    "    complexities = all_metrics.sel(metric=\"complexity\").values.astype(int)\n",
    "    lower_complexity = complexities.min()\n",
    "    upper_complexity = complexities.max()\n",
    "    \n",
    "    # plot\n",
    "    # set up subplots\n",
    "    n_rows = 2\n",
    "    n_cols = 2\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(12,8), layout='compressed')\n",
    "    Ks = all_metrics.K.values.reshape((n_rows, n_cols))\n",
    "\n",
    "    for col in range(n_cols):\n",
    "        for row in range(n_rows):\n",
    "            ax = axs[row, col]\n",
    "            K = Ks[row, col]\n",
    "            # extract data at particular K\n",
    "            data = all_metrics.sel(K=K)\n",
    "            complexities = data.sel(metric=\"complexity\").values.astype(int)\n",
    "            complexity_counts = np.trim_zeros(np.bincount(complexities))\n",
    "            rmse_pred = data.sel(metric=\"predictive error\").values\n",
    "            rmse_true = data.sel(metric=\"coefficient error\").values\n",
    "\n",
    "            # plot data\n",
    "            ax.set_title(f\"K = {K}\")\n",
    "            \n",
    "            # complexity ticks only integers\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "            bar_args = (range(lower_complexity, upper_complexity+1), complexity_counts)\n",
    "            bar_kwargs = {\"width\": 0.5}\n",
    "            scatter_args = (complexities, rmse_pred)\n",
    "            scatter_kwargs = {\"s\": 96.}\n",
    "            if plot_model_pareto:\n",
    "                bar_kwargs.update({\"edgecolor\": \"purple\", \"color\": \"None\"})\n",
    "            if use_color:\n",
    "                scatter_kwargs.update({\"c\": rmse_true})\n",
    "            \n",
    "            # plot which data is desired\n",
    "            if plot_num_models:\n",
    "                # histogram of number of models w certain number of terms\n",
    "                ax.bar(*bar_args, **bar_kwargs)\n",
    "                if plot_model_pareto:\n",
    "                    # scatter plot of models and error\n",
    "                    ax_right = ax.twinx()\n",
    "                    im = ax_right.scatter(*scatter_args, **scatter_kwargs)\n",
    "                    # set shared axis for predictive error\n",
    "                    ax_right.set_ylim(lower_pred, upper_pred)\n",
    "                    if col==0:\n",
    "                        ax_right.set_yticks([])\n",
    "            else:\n",
    "                im = ax.scatter(*scatter_args, **scatter_kwargs)\n",
    "\n",
    "    # figure-level labels\n",
    "    fig.supxlabel(\"Number of terms\")\n",
    "    right_axis_label_offset = 1.03\n",
    "\n",
    "    # plot true coefficient error colorbar if using\n",
    "    if plot_model_pareto and use_color: \n",
    "        fig.colorbar(im, ax=axs, label=\"True coefficient error\", pad=0.08, shrink=0.8)\n",
    "        right_axis_label_offset = 0.86\n",
    "\n",
    "    if plot_num_models:\n",
    "        fig.supylabel(\"Number of models\")\n",
    "        if plot_model_pareto:\n",
    "            fig.text(x=right_axis_label_offset, y=0.5, s=\"Predictive error\", rotation=90, ha='center', va='center')\n",
    "    else:\n",
    "        fig.supylabel(\"Predictive error\")\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_results(all_metrics, True, True, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.11 ('yukawa-sindy-vetted')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "98d46e98f64ee163222527ccb20c076c625615c644e0fce1ec07415ec7d302a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
